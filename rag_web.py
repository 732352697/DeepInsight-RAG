import streamlit as st
import os
import tempfile
import sys
import docx
import pptx
import openpyxl
import time
import random  # ç”¨æ¥æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´çš„æ³¢åŠ¨

# ğŸ›¡ï¸ å¼ºåˆ¶ç¦ç”¨ä»£ç†
os.environ["NO_PROXY"] = "localhost,127.0.0.1,0.0.0.0"

from langchain_ollama import ChatOllama
from langchain_community.document_loaders import PyPDFLoader

# --- 1. é¡µé¢é…ç½® (DeepSeek é£æ ¼) ---
st.set_page_config(
    page_title="DeepInsight R1",
    page_icon="ğŸ§ ",
    layout="wide"
)

# æ³¨å…¥ CSS è®©çŠ¶æ€æ¡†æ›´å¥½çœ‹
st.markdown("""
<style>
    .stStatusWidget {box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-radius: 10px;}
    .reportview-container {margin-top: -2em;}
    header {visibility: hidden;}
    .stDeployButton {display:none;}
</style>
""", unsafe_allow_html=True)

st.title("ğŸ§  DeepInsight Â· æ·±åº¦æ€è€ƒç‰ˆ")
st.caption("ğŸš€ æœ¬åœ° RAG çŸ¥è¯†åº“ | ä»¿ DeepSeek æ€è€ƒäº¤äº’æ¨¡å¼")

# --- 2. ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ“‚ çŸ¥è¯†åº“ç®¡ç†")
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ èµ„æ–™ (å¤šé€‰)",
        type=["pdf", "docx", "xlsx", "pptx"],
        accept_multiple_files=True
    )

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºè®°å¿†"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

    st.info("ğŸ’¡ æç¤ºï¼šä¸Šä¼ æ–‡ä»¶è¶Šå¤šï¼Œæ€è€ƒæ—¶é—´å¯èƒ½ä¼šè¶Šé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…â€œæ·±åº¦æ€è€ƒâ€å®Œæˆã€‚")


# --- 3. æ ¸å¿ƒè§£æé€»è¾‘ ---
def extract_text_from_file(uploaded_file):
    file_ext = uploaded_file.name.split(".")[-1].lower()
    text = ""
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_ext}") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    try:
        if file_ext == "pdf":
            loader = PyPDFLoader(tmp_file_path)
            pages = loader.load()
            text = "\n".join([p.page_content for p in pages])
        elif file_ext == "docx":
            doc = docx.Document(tmp_file_path)
            text = "\n".join([para.text for para in doc.paragraphs])
        elif file_ext == "xlsx":
            wb = openpyxl.load_workbook(tmp_file_path, data_only=True)
            for sheet in wb.sheetnames:
                ws = wb[sheet]
                text += f"\n[Sheet: {sheet}]\n"
                for row in ws.iter_rows(values_only=True):
                    row_text = " | ".join([str(cell) for cell in row if cell is not None])
                    text += row_text + "\n"
        elif file_ext == "pptx":
            prs = pptx.Presentation(tmp_file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        text += shape.text + "\n"
        return text
    except Exception as e:
        return f"è§£æå¼‚å¸¸: {str(e)}"
    finally:
        if os.path.exists(tmp_file_path):
            os.remove(tmp_file_path)


# --- 4. æ–‡ä»¶å¤„ç† ---
if uploaded_files:
    current_file_names = ",".join([f.name for f in uploaded_files])
    if "last_processed_files" not in st.session_state or st.session_state.last_processed_files != current_file_names:
        combined_text = ""
        progress_bar = st.progress(0)
        status_text = st.empty()

        for i, file in enumerate(uploaded_files):
            status_text.text(f"æ­£åœ¨è¯»å–: {file.name}...")
            file_text = extract_text_from_file(file)
            combined_text += f"\n\n=== ğŸ“„ {file.name} ===\n{file_text}\n"
            progress_bar.progress((i + 1) / len(uploaded_files))

        if len(combined_text) > 10000:
            combined_text = combined_text[:10000]

        st.session_state.doc_text = combined_text
        st.session_state.last_processed_files = current_file_names
        progress_bar.empty()
        status_text.empty()
        st.toast(f"âœ… çŸ¥è¯†åº“åŠ è½½å®Œæ¯•ï¼Œå…± {len(combined_text)} å­—", icon="ğŸ§ ")

# --- 5. èŠå¤©ç•Œé¢ (DeepSeek é£æ ¼æ ¸å¿ƒåŒº) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    avatar = "ğŸ§‘â€ğŸ’»" if msg["role"] == "user" else "ğŸ§ "
    with st.chat_message(msg["role"], avatar=avatar):
        st.markdown(msg["content"])

if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(prompt)

    if "doc_text" in st.session_state:
        with st.chat_message("assistant", avatar="ğŸ§ "):

            # ğŸŒŸ 1. DeepSeek é£æ ¼çš„çŠ¶æ€å±•ç¤ºå®¹å™¨ ğŸŒŸ
            # è¿™ä¸ªå®¹å™¨ä¼šåœ¨ç”Ÿæˆå‰æ˜¾ç¤ºï¼Œè®©ç”¨æˆ·è§‰å¾—â€œå®ƒåœ¨æ€è€ƒâ€
            with st.status("ğŸš€ æ­£åœ¨è¿›è¡Œæ·±åº¦æ€è€ƒ...", expanded=True) as status:
                st.write("ğŸ” æ­£åœ¨æ£€ç´¢æœ¬åœ°çŸ¥è¯†åº“ç´¢å¼•...")
                time.sleep(0.3)  # å‡è£…ä¸€ç‚¹å»¶è¿Ÿï¼Œè®©ç”¨æˆ·çœ‹æ¸…æ­¥éª¤

                # å±•ç¤ºå®ƒæ‰¾åˆ°äº†ä»€ä¹ˆï¼ˆå¢å¼ºä¿¡ä»»æ„Ÿï¼‰
                doc_snippet = st.session_state.doc_text[:300].replace("\n", " ") + "..."
                st.write(f"ğŸ“– å·²æå–ä¸Šä¸‹æ–‡ (å…± {len(st.session_state.doc_text)} å­—)")
                st.code(doc_snippet, language="text")

                st.write("âš™ï¸ æ­£åœ¨æ„å»ºæç¤ºè¯å·¥ç¨‹ (Prompt Engineering)...")
                time.sleep(0.2)

                st.write("ğŸ§  æ¨¡å‹æ­£åœ¨è¿›è¡Œé€»è¾‘æ¨ç†...")

                # å‡†å¤‡å¼€å§‹ç”Ÿæˆ
                message_placeholder = st.empty()
                full_response = ""

                try:
                    llm = ChatOllama(
                        model="qwen2.5:1.5b",
                        temperature=0.1,  # ä½æ¸©ï¼Œä¿è¯äº‹å®å‡†ç¡®
                        base_url="http://127.0.0.1:11434"
                    )

                    final_prompt = f"""
                    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åˆ†æåŠ©æ‰‹ã€‚è¯·åŸºäºä¸‹é¢çš„ã€å‚è€ƒæ–‡æ¡£ã€‘ï¼Œè¿›è¡Œæ·±åº¦æ€è€ƒå¹¶å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

                    ã€å‚è€ƒæ–‡æ¡£ã€‘ï¼š
                    {st.session_state.doc_text}

                    ã€ç”¨æˆ·é—®é¢˜ã€‘ï¼š
                    {prompt}

                    è¯·æ³¨æ„ï¼šå¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·ç›´æ¥è¯´æ˜ã€‚
                    """

                    chunks = llm.stream(final_prompt)

                    # åˆ¹è½¦ç‰‡æœºåˆ¶ (ä¿ç•™ï¼Œé˜²å´©)
                    last_update_time = 0

                    for chunk in chunks:
                        if chunk.content:
                            full_response += chunk.content
                            current_time = time.time()
                            if current_time - last_update_time > 0.05:
                                message_placeholder.markdown(full_response)
                                last_update_time = current_time

                    message_placeholder.markdown(full_response)

                    # ğŸŒŸ 2. æ€è€ƒå®Œæˆï¼Œæ›´æ–°çŠ¶æ€æ¡† ğŸŒŸ
                    status.update(label="âœ… æ·±åº¦æ€è€ƒå®Œæˆ", state="complete", expanded=False)

                    st.session_state.messages.append({"role": "assistant", "content": full_response})

                except Exception as e:
                    status.update(label="âŒ æ€è€ƒè¿‡ç¨‹å‡ºé”™", state="error")
                    st.error(f"é”™è¯¯: {str(e)}")
    else:
        st.warning("è¯·å…ˆä¸Šä¼ æ–‡æ¡£ï¼Œæˆ‘æ‰èƒ½å¼€å§‹æ€è€ƒã€‚")